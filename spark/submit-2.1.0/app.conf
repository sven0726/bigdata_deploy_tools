spark.opentsdb.host=192.168.37.35
spark.opentsdb.port=4242
spark.mongo.addr=192.168.47.40:37218,192.168.47.41:37218,192.168.47.42:37218
spark.mongo.db=qbox_bi
spark.fopg.mongo.addr=192.168.47.51:2701,192.168.47.52:2701,192.168.47.53:2701
spark.fopg.mongo.db=qbox_bi_rt
spark.pili.mongo.addr=192.168.47.51:2702,192.168.47.52:2702,192.168.47.53:2702
spark.pili.mongo.db=qbox_pili
spark.domain.query.addr=192.168.34.29:23200
spark.apicode.ignore.addr=192.168.47.35:9988
spark.logmatch.addr=192.168.47.35:4570

spark.io.new.mongo.addr=192.168.47.51:2702,192.168.47.52:2702,192.168.47.53:2702
spark.io.new.mongo.db=qbox_io
spark.io.new.mongo.coll=rt_io_5min

spark.ui.port=4041
spark.driver.cores=4
spark.driver.memory=4g
spark.executor.memory=10g
spark.cores.max=116
spark.eventLog.enabled=false
spark.eventLog.dir=/home/qboxserver/spark_events
spark.shuffle.consolidateFiles=true
spark.akka.threads=4
spark.driver.extraJavaOptions=-XX:+UseConcMarkSweepGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps
spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintAdaptiveSizePolicy
spark.speculation=false
spark.streaming.blockInterval=1200
spark.default.parallelism=24
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.streaming.backpressure.enabled=true
spark.memory.useLegacyMode=true
spark.storage.memoryFraction=0.7
spark.storage.unrollFraction=0.3
spark.streaming.concurrentJobs=1
spark.streaming.blockQueueSize=2
spark.cleaner.ttl=600
spark.streaming.stopGracefullyOnShutdown=true

spark.rdd.duration.second=20
spark.stream.remember.second=300
spark.stream.num=20
spark.stream.parallelism=1

spark.kafka.topics=all-log,nb-log
spark.kafka.consumer.zookeeper.connect=localhost:2181
spark.kafka.consumer.group.id=spark-streaming-group-4
spark.kafka.consumer.zookeeper.connection.timeout.ms=10000
spark.kafka.consumer.num.consumer.fetchers=1
spark.kafka.consumer.rebalance.max.retries=3
spark.kafka.consumer.rebalance.backoff.ms=4000
spark.kafka.consumer.zookeeper.session.timeout.ms=9000
spark.kafka.consumer.metadata.broker.list=localhost:9092
spark.kafka.producer.metadata.broker.list=localhost:9092
spark.kafka.producer.request.required.acks=1
